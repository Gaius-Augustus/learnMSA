{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa051867-9795-470c-8e0a-2080690f40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('../learnMSA')\n",
    "import numpy as np\n",
    "from learnMSA import msa_hmm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c715bf4-a1bb-40b3-95bf-67a61b1916fa",
   "metadata": {},
   "source": [
    "## MSA HMM Interactive\n",
    "\n",
    "1. Fit n models, keep the best and align\n",
    "2. Compare to a reference\n",
    "3. Visualize the HMM\n",
    "\n",
    "Change the variables in the following cell to fit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59efc747-cd9a-47bc-a38c-ad654566b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fasta file with unaligned sequences.\n",
    "train_filename = \"test/data/egf.fasta\"\n",
    "\n",
    "# Reference file with aligned sequences that have matching IDs to (potentially a subset of) the \n",
    "# sequences in the train_file.\n",
    "# Replace with empty string if no reference is available.\n",
    "ref_filename = \"test/data/egf.ref\"\n",
    "\n",
    "# The number of independently trained models.\n",
    "num_models = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e9512-4a21-4288-b94f-863012b5ec52",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3484e00-40ed-46a9-a493-1f583bb00373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of 10 models on file egf.fasta\n",
      "Configuration: \n",
      "{\n",
      "num_models : 10\n",
      "transitioner : ProfileHMMTransitioner(\n",
      " transition_init=\n",
      "    {\n",
      "    begin_to_match : DefaultEntry() , match_to_end : DefaultExit() , \n",
      "    match_to_match : DefaultMatchTransition(1) , match_to_insert : DefaultMatchTransition(-1) , \n",
      "    insert_to_match : Norm(0, 0.1) , insert_to_insert : Norm(-0.5, 0.1) , \n",
      "    match_to_delete : DefaultMatchTransition(-1) , delete_to_match : Norm(0, 0.1) , \n",
      "    delete_to_delete : Norm(-0.5, 0.1) , left_flank_loop : Norm(0, 0.1) , \n",
      "    left_flank_exit : Norm(-1, 0.1) , right_flank_loop : Norm(0, 0.1) , \n",
      "    right_flank_exit : Norm(-1, 0.1) , unannotated_segment_loop : Norm(0, 0.1) , \n",
      "    unannotated_segment_exit : Norm(-1, 0.1) , end_to_unannotated_segment : Norm(-9, 0.1) , \n",
      "    end_to_right_flank : Norm(0, 0.1) , end_to_terminal : Norm(0, 0.1)\n",
      "    },\n",
      " flank_init=Const(0.0),\n",
      " prior=ProfileHMMTransitionPrior(match_comp=1, insert_comp=1, delete_comp=1, alpha_flank=7000, alpha_single=1000000000.0, alpha_frag=10000.0),\n",
      " frozen_kernels={})\n",
      "emitter : ProfileHMMEmitter(\n",
      " emission_init=DefaultEmission(),\n",
      " insertion_init=Const(shape=(25,)),\n",
      " prior=AminoAcidPrior(comp_count=1),\n",
      " frozen_insertions=True, )\n",
      "max_surgery_runs : 4\n",
      "length_init_quantile : 0.5\n",
      "surgery_quantile : 0.5\n",
      "min_surgery_seqs : 10000.0\n",
      "len_mul : 0.8\n",
      "batch_size : <function get_adaptive_batch_size at 0x7f42083fbc10>\n",
      "learning_rate : 0.1\n",
      "epochs : [10, 2, 10]\n",
      "use_prior : True\n",
      "dirichlet_mix_comp_count : 1\n",
      "use_anc_probs : True\n",
      "trainable_rate_matrices : False\n",
      "surgery_del : 0.5\n",
      "surgery_ins : 0.5\n",
      "num_rate_matrices : 1\n",
      "per_matrix_rate : False\n",
      "matrix_rate_l2 : 0.0\n",
      "shared_rate_matrix : False\n",
      "equilibrium_sample : False\n",
      "transposed : False\n",
      "encoder_initializer : [Const(-3), Const(shape=(10, 20, 20)), Const(shape=(10, 20))]\n",
      "model_criterion : consensus\n",
      "encoder_weight_extractor : None\n",
      "allow_user_keys_in_config : False\n",
      "}\n",
      "Fitting models of lengths [18 23 15 27 20 23 24 22 27 28] on 7774 sequences.\n",
      "Batch size= 512 Learning rate= 0.1\n",
      "Using 1 GPUs.\n",
      "Epoch 1/10\n",
      "17/17 - 18s - loss: 97.6001 - loglik: -9.3188e+01 - logprior: -4.4118e+00\n",
      "Epoch 2/10\n",
      "17/17 - 2s - loss: 77.2982 - loglik: -7.5820e+01 - logprior: -1.4783e+00\n",
      "Epoch 3/10\n",
      "17/17 - 1s - loss: 68.3213 - loglik: -6.6788e+01 - logprior: -1.5330e+00\n",
      "Epoch 4/10\n",
      "17/17 - 2s - loss: 66.5044 - loglik: -6.4985e+01 - logprior: -1.5198e+00\n",
      "Epoch 5/10\n",
      "17/17 - 2s - loss: 65.8950 - loglik: -6.4467e+01 - logprior: -1.4284e+00\n",
      "Epoch 6/10\n",
      "17/17 - 1s - loss: 65.6459 - loglik: -6.4219e+01 - logprior: -1.4272e+00\n",
      "Epoch 7/10\n",
      "17/17 - 1s - loss: 65.6521 - loglik: -6.4239e+01 - logprior: -1.4133e+00\n",
      "expansions model 0: [(7, 1), (8, 1), (9, 2), (10, 9), (11, 1), (12, 3)]\n",
      "discards model 0: [0]\n",
      "expansions model 1: [(7, 1), (10, 1), (11, 3), (12, 4), (13, 1), (14, 1)]\n",
      "discards model 1: [0]\n",
      "expansions model 2: [(13, 9), (15, 10)]\n",
      "discards model 2: [0]\n",
      "expansions model 3: [(2, 2), (12, 2), (13, 2), (19, 1), (21, 1)]\n",
      "discards model 3: [0]\n",
      "expansions model 4: [(7, 1), (10, 1), (11, 9), (12, 1), (14, 2)]\n",
      "discards model 4: [0]\n",
      "expansions model 5: [(2, 4), (10, 2), (11, 3), (12, 1), (13, 1), (14, 1)]\n",
      "discards model 5: [0]\n",
      "expansions model 6: [(0, 1), (1, 2), (2, 2), (10, 2), (11, 2), (13, 2), (16, 1), (18, 1)]\n",
      "discards model 6: []\n",
      "expansions model 7: [(2, 2), (10, 1), (11, 7), (12, 1), (13, 1)]\n",
      "discards model 7: [0]\n",
      "expansions model 8: [(2, 2), (12, 2), (13, 2), (19, 1), (21, 1)]\n",
      "discards model 8: [0]\n",
      "expansions model 9: [(2, 2), (12, 2), (14, 2), (19, 1)]\n",
      "discards model 9: [0]\n",
      "Re-initialized the encoder parameters.\n",
      "Fitting models of lengths [34 33 33 34 33 34 37 33 34 34] on 7774 sequences.\n",
      "Batch size= 512 Learning rate= 0.1\n",
      "Using 1 GPUs.\n",
      "Epoch 1/2\n",
      "17/17 - 17s - loss: 70.4673 - loglik: -6.4934e+01 - logprior: -5.5332e+00\n",
      "Epoch 2/2\n",
      "17/17 - 2s - loss: 61.0579 - loglik: -5.8510e+01 - logprior: -2.5478e+00\n",
      "expansions model 0: [(0, 1)]\n",
      "discards model 0: [10 17 26]\n",
      "expansions model 1: [(0, 1)]\n",
      "discards model 1: [13 14]\n",
      "expansions model 2: [(0, 1)]\n",
      "discards model 2: [18 19]\n",
      "expansions model 3: []\n",
      "discards model 3: [ 0 14 16]\n",
      "expansions model 4: [(0, 1)]\n",
      "discards model 4: [16 25]\n",
      "expansions model 5: [(0, 1)]\n",
      "discards model 5: [ 0 17]\n",
      "expansions model 6: []\n",
      "discards model 6: [ 0  3  5 16 19 22]\n",
      "expansions model 7: []\n",
      "discards model 7: [ 0 17]\n",
      "expansions model 8: []\n",
      "discards model 8: [ 0 14 16]\n",
      "expansions model 9: []\n",
      "discards model 9: [ 0 14 17]\n",
      "Re-initialized the encoder parameters.\n",
      "Fitting models of lengths [32 32 32 31 32 33 31 31 31 31] on 7774 sequences.\n",
      "Batch size= 512 Learning rate= 0.1\n",
      "Using 1 GPUs.\n",
      "Epoch 1/2\n",
      "17/17 - 17s - loss: 62.0299 - loglik: -5.7543e+01 - logprior: -4.4865e+00\n",
      "Epoch 2/2\n",
      "17/17 - 2s - loss: 58.2054 - loglik: -5.6627e+01 - logprior: -1.5788e+00\n",
      "expansions model 0: []\n",
      "discards model 0: [0]\n",
      "expansions model 1: []\n",
      "discards model 1: [0]\n",
      "expansions model 2: []\n",
      "discards model 2: [0]\n",
      "expansions model 3: []\n",
      "discards model 3: []\n",
      "expansions model 4: []\n",
      "discards model 4: [0]\n",
      "expansions model 5: []\n",
      "discards model 5: [0]\n",
      "expansions model 6: []\n",
      "discards model 6: []\n",
      "expansions model 7: []\n",
      "discards model 7: []\n",
      "expansions model 8: []\n",
      "discards model 8: []\n",
      "expansions model 9: []\n",
      "discards model 9: []\n",
      "Re-initialized the encoder parameters.\n",
      "Fitting models of lengths [31 31 31 31 31 32 31 31 31 31] on 7774 sequences.\n",
      "Batch size= 512 Learning rate= 0.1\n",
      "Using 1 GPUs.\n",
      "Epoch 1/10\n",
      "17/17 - 17s - loss: 61.9521 - loglik: -5.7667e+01 - logprior: -4.2847e+00\n",
      "Epoch 2/10\n",
      "17/17 - 2s - loss: 58.4012 - loglik: -5.6820e+01 - logprior: -1.5814e+00\n",
      "Epoch 3/10\n",
      "17/17 - 2s - loss: 57.9471 - loglik: -5.6601e+01 - logprior: -1.3465e+00\n",
      "Epoch 4/10\n",
      "17/17 - 2s - loss: 57.8136 - loglik: -5.6529e+01 - logprior: -1.2845e+00\n",
      "Epoch 5/10\n",
      "17/17 - 2s - loss: 57.7160 - loglik: -5.6467e+01 - logprior: -1.2485e+00\n",
      "Epoch 6/10\n",
      "17/17 - 2s - loss: 57.6774 - loglik: -5.6452e+01 - logprior: -1.2256e+00\n",
      "Epoch 7/10\n",
      "17/17 - 2s - loss: 57.6816 - loglik: -5.6474e+01 - logprior: -1.2077e+00\n",
      "Time for alignment: 117.2790\n",
      "Consensus scores:  ['-35.0673', '-35.1870', '-35.2213', '-35.2316', '-34.9532', '-40.2513', '-34.9710', '-35.6218', '-35.1625', '-35.0227']\n",
      "Selection criterion: consensus\n",
      "Best model:  4 (0-based)\n",
      "time for generating output: 0.6057\n",
      "Wrote file test/data/interactive.alignment.fasta\n",
      "Model 0 SP score = 0.7610961018911617\n",
      "Model 1 SP score = 0.7610961018911617\n",
      "Model 2 SP score = 0.7568506368197607\n",
      "Model 3 SP score = 0.7610961018911617\n",
      "Model 4 SP score = 0.7672713238131995\n",
      "Model 5 SP score = 0.748745658047086\n",
      "Model 6 SP score = 0.7610961018911617\n",
      "Model 7 SP score = 0.7672713238131995\n",
      "Model 8 SP score = 0.7580084909301428\n",
      "Model 9 SP score = 0.7630258587417985\n"
     ]
    }
   ],
   "source": [
    "out_filename = \"test/data/interactive.alignment.fasta\"\n",
    "config = msa_hmm.config.make_default(num_models)\n",
    "config[\"model_criterion\"] = \"consensus\"\n",
    "alignment_model, r = msa_hmm.align.run_learnMSA(train_filename,\n",
    "                                                  out_filename,\n",
    "                                                  config, \n",
    "                                                  ref_filename=ref_filename, \n",
    "                                                  verbose=True,\n",
    "                                                  select_best_for_comparison=False)\n",
    "msa_hmm.vis.print_and_plot(alignment_model, alignment_model.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffabfc-4c3e-4229-a912-1aa7b779ccfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=32000, mem_mib=30518, disk_mb=1000, disk_mib=954, gpu=1
Select jobs to execute...

[Thu Dec 14 14:28:16 2023]
rule test_prior:
    input: train_prior_outputs/protT5_16_softmax_32.out
    output: results/test_prior_rows/protT5_16_softmax_32
    jobid: 0
    reason: Missing output files: results/test_prior_rows/protT5_16_softmax_32
    wildcards: lm=protT5, dimension=16, activation=softmax, num_components=32
    threads: 4
    resources: mem_mb=32000, mem_mib=30518, disk_mb=1000, disk_mib=954, tmpdir=/tmp, partition=vision, gpu=1, runtime=60


        cd .. && python3 TestPrior.py --lm protT5 --reduced_dim 16             --activation softmax --components 32 --unscaled > train_scoring_models/results/test_prior_rows/protT5_16_softmax_32
        
Traceback (most recent call last):
  File "/home/beckerf/tmp_work/learnMSA/learnMSA/protein_language_models/TestPrior.py", line 48, in <module>
    for batch in test_ds.take(steps-1):
  File "/home/beckerf/mambaforge/envs/snakeMSA/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py", line 766, in __next__
    return self._next_internal()
  File "/home/beckerf/mambaforge/envs/snakeMSA/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py", line 749, in _next_internal
    ret = gen_dataset_ops.iterator_get_next(
  File "/home/beckerf/mambaforge/envs/snakeMSA/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py", line 3017, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File "/home/beckerf/mambaforge/envs/snakeMSA/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.UnknownError: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} IndexError: index 936 is out of bounds for axis 0 with size 936
Traceback (most recent call last):

  File "/home/beckerf/mambaforge/envs/snakeMSA/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py", line 271, in __call__
    ret = func(*args)

  File "/home/beckerf/mambaforge/envs/snakeMSA/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 642, in wrapper
    return func(*args, **kwargs)

  File "/home/beckerf/mambaforge/envs/snakeMSA/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 1035, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/home/beckerf/tmp_work/learnMSA/learnMSA/protein_language_models/../../learnMSA/protein_language_models/DataPipeline.py", line 300, in _gen_inputs
    yield _tokenize_column_prior(encoder, *_make_column_prior_batch(batch_clans[i*batch_size : (i+1)*batch_size],

  File "/home/beckerf/tmp_work/learnMSA/learnMSA/protein_language_models/../../learnMSA/protein_language_models/DataPipeline.py", line 179, in _make_column_prior_batch
    match_mask = (column_occupancies > 0.5)[cols].astype(np.float32)

IndexError: index 936 is out of bounds for axis 0 with size 936


	 [[{{node PyFunc}}]] [Op:IteratorGetNext]
[Thu Dec 14 14:29:18 2023]
Error in rule test_prior:
    jobid: 0
    input: train_prior_outputs/protT5_16_softmax_32.out
    output: results/test_prior_rows/protT5_16_softmax_32

RuleException:
CalledProcessError in file /home/beckerf/tmp_work/learnMSA/learnMSA/protein_language_models/train_scoring_models/Snakefile, line 90:
Command 'set -euo pipefail;  
        cd .. && python3 TestPrior.py --lm protT5 --reduced_dim 16             --activation softmax --components 32 --unscaled > train_scoring_models/results/test_prior_rows/protT5_16_softmax_32' returned non-zero exit status 1.
  File "/home/beckerf/tmp_work/learnMSA/learnMSA/protein_language_models/train_scoring_models/Snakefile", line 90, in __rule_test_prior
  File "/home/beckerf/mambaforge/envs/snakeMSA/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Removing output files of failed job test_prior since they might be corrupted:
results/test_prior_rows/protT5_16_softmax_32
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message

Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=32000, mem_mib=30518, disk_mb=1000, disk_mib=954, gpu=1
Select jobs to execute...

[Sat Dec 16 04:05:39 2023]
rule test_prior:
    input: train_prior_outputs/protT5_32_softmax_32.out
    output: results/test_prior_rows/protT5_32_softmax_32
    jobid: 0
    reason: Missing output files: results/test_prior_rows/protT5_32_softmax_32
    wildcards: lm=protT5, dimension=32, activation=softmax, num_components=32
    threads: 4
    resources: mem_mb=32000, mem_mib=30518, disk_mb=1000, disk_mib=954, tmpdir=/tmp, partition=vision, gpu=1, runtime=60


        cd .. && python3 TestPrior.py --lm protT5 --reduced_dim 32             --activation softmax --components 32 --unscaled > train_scoring_models/results/test_prior_rows/protT5_32_softmax_32
        
[Sat Dec 16 04:06:38 2023]
Finished job 0.
1 of 1 steps (100%) done

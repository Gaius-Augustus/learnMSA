Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=100000, mem_mib=95368, disk_mb=1000, disk_mib=954, gpu=1
Select jobs to execute...

[Sun Nov 26 20:31:14 2023]
rule train_prior:
    input: train_scoring_model_outputs/proteinBERT_64_sigmoid.out
    output: train_prior_outputs/proteinBERT_64_sigmoid_100.out
    jobid: 0
    reason: Missing output files: train_prior_outputs/proteinBERT_64_sigmoid_100.out
    wildcards: lm=proteinBERT, dimension=64, activation=sigmoid, num_components=100
    threads: 4
    resources: mem_mb=100000, mem_mib=95368, disk_mb=1000, disk_mib=954, tmpdir=/tmp, partition=vision, gpu=1, runtime=2880


        cd .. && python3 PretrainMultivariateNormalPrior.py --lm proteinBERT --reduced_dim 64             --activation sigmoid --components 100 > train_scoring_models/train_prior_outputs/proteinBERT_64_sigmoid_100.out
        
2023-11-26 20:31:14.531803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-26 20:32:00.283941: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-26 20:33:57.423132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78968 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:c1:00.0, compute capability: 8.0
2023-11-26 20:37:24.006478: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x55aa53ecfe70
2023-11-26 20:40:49.275341: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-11-26 20:41:19.462029: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800
2023-11-26 20:43:16.575517: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2023-11-26 20:43:16.578701: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2023-11-26 20:43:16.578725: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version
2023-11-26 20:43:16.579621: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2023-11-26 20:43:16.579700: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
[Sun Nov 26 21:23:46 2023]
Finished job 0.
1 of 1 steps (100%) done

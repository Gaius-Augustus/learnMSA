{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ab05b-4bf0-48d3-bf1c-7c27050852f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install t-coffee mmseqs2 -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f067659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 14:20:21.540775: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-14 14:20:21.554328: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-14 14:20:21.558619: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-14 14:20:21.569980: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-14 14:20:22.127071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728915622.792394   79222 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-14 14:20:22.817738: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from learnMSA.msa_hmm import Configuration, Align, Visualize\n",
    "from learnMSA.msa_hmm.SequenceDataset import SequenceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c715bf4-a1bb-40b3-95bf-67a61b1916fa",
   "metadata": {},
   "source": [
    "## learnMSA demo\n",
    "\n",
    "In this notebook, we will fit a number of HMM models to a dataset of unaligned sequences. \n",
    "We will then use the fitted models to align the sequences and compare the results.\n",
    "Moreover, we will visualize the best (according to an objective criterion) model and alignment.\n",
    "\n",
    "*This notebook is meant to be a demo for running learnMSA in Python code. Check the readme if you want to run learnMSA from the command line.* \n",
    "\n",
    "Change the variables in the following cell to fit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59efc747-cd9a-47bc-a38c-ad654566b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fasta file with unaligned sequences.\n",
    "\n",
    "train_filename = \"test/data/egf.fasta\"\n",
    "\n",
    "# Reference file with aligned sequences that have matching IDs to (potentially a subset of) the \n",
    "# sequences in the train_file.\n",
    "# Replace with empty string if no reference is available.\n",
    "ref_filename = \"test/data/egf.ref\"\n",
    "\n",
    "# The number of independently trained models.\n",
    "num_models = 4\n",
    "\n",
    "# Use sequence weights based on a rapid pre-clustering of the sequences (requires mmseqs2 to be installed)\n",
    "use_weights = True\n",
    "\n",
    "# Align long insertions with an external aligner left unaligned by the main MSA stage (requires famsa to be installed).\n",
    "align_insertions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e9512-4a21-4288-b94f-863012b5ec52",
   "metadata": {},
   "source": [
    "## Run learnMSA from Python (Training + Viterbi alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a47ebb-cc04-4303-9194-6df7d9fe7bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of 4 models on file egf.fasta\n",
      "Configuration: \n",
      "{\n",
      "num_models : 4\n",
      "transitioner : ProfileHMMTransitioner(\n",
      " transition_init=\n",
      "    {\n",
      "    begin_to_match : DefaultEntry() , match_to_end : DefaultExit() , \n",
      "    match_to_match : DefaultMatchTransition(1) , match_to_insert : DefaultMatchTransition(-1) , \n",
      "    insert_to_match : Norm(0, 0.1) , insert_to_insert : Norm(-0.5, 0.1) , \n",
      "    match_to_delete : DefaultMatchTransition(-1) , delete_to_match : Norm(0, 0.1) , \n",
      "    delete_to_delete : Norm(-0.5, 0.1) , left_flank_loop : Norm(0, 0.1) , \n",
      "    left_flank_exit : Norm(-1, 0.1) , right_flank_loop : Norm(0, 0.1) , \n",
      "    right_flank_exit : Norm(-1, 0.1) , unannotated_segment_loop : Norm(0, 0.1) , \n",
      "    unannotated_segment_exit : Norm(-1, 0.1) , end_to_unannotated_segment : Norm(-9, 0.1) , \n",
      "    end_to_right_flank : Norm(0, 0.1) , end_to_terminal : Norm(0, 0.1)\n",
      "    },\n",
      " flank_init=Const(0.0),\n",
      " prior=ProfileHMMTransitionPrior(match_comp=1, insert_comp=1, delete_comp=1, alpha_flank=7000, alpha_single=1000000000.0, alpha_global=10000.0, alpha_flank_compl=1, alpha_single_compl=1, alpha_global_compl=1),\n",
      " frozen_kernels={})\n",
      "emitter : ProfileHMMEmitter(\n",
      " emission_init=EmissionInitializer(),\n",
      " insertion_init=Const(shape=(23,)),\n",
      " prior=AminoAcidPrior(comp_count=1),\n",
      " frozen_insertions=True, )\n",
      "max_surgery_runs : 4\n",
      "length_init_quantile : 0.5\n",
      "surgery_quantile : 0.5\n",
      "min_surgery_seqs : 100000.0\n",
      "len_mul : 0.8\n",
      "batch_size : functools.partial(<function get_adaptive_batch_size at 0x7f8d98654680>, small_gpu=False)\n",
      "learning_rate : 0.1\n",
      "epochs : [10, 2, 10]\n",
      "crop_long_seqs : inf\n",
      "use_prior : True\n",
      "dirichlet_mix_comp_count : 1\n",
      "use_anc_probs : True\n",
      "trainable_rate_matrices : False\n",
      "trainable_distances : True\n",
      "surgery_del : 0.5\n",
      "surgery_ins : 0.5\n",
      "num_rate_matrices : 1\n",
      "per_matrix_rate : False\n",
      "matrix_rate_l2 : 0.0\n",
      "shared_rate_matrix : False\n",
      "equilibrium_sample : False\n",
      "transposed : False\n",
      "encoder_initializer : [Const(-3), Const(shape=(4, 1, 20, 20)), Const(shape=(4, 1, 20))]\n",
      "model_criterion : AIC\n",
      "encoder_weight_extractor : None\n",
      "experimental_evolve_upper_half : False\n",
      "cluster_seq_id : 0.9\n",
      "use_language_model : False\n",
      "frozen_insertions : True\n",
      "allow_user_keys_in_config : False\n",
      "}\n",
      "Fitting models of lengths [23 24 25 21] on 7774 sequences.\n",
      "Batch size= 512 Learning rate= 0.1\n",
      "Using sequence weights  [1.         0.33333334 0.05882353 ... 0.05555556 0.03030303 0.25      ] .\n",
      "Using 0 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728915628.965604   79222 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-14 14:20:28.965867: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728915631.681727   79222 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-14 14:20:31.681985: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/beckerf/mambaforge/envs/learnMSAdev2/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:731: UserWarning: Gradients do not exist for variables ['emission_kernel_0', 'emission_kernel_1', 'emission_kernel_2', 'emission_kernel_3', 'transition_kernel_begin_to_match_0', 'transition_kernel_match_to_end_1', 'transition_kernel_match_to_match_2', 'transition_kernel_match_to_insert_3', 'transition_kernel_insert_to_match_4', 'transition_kernel_insert_to_insert_5', 'transition_kernel_match_to_delete_6', 'transition_kernel_delete_to_match_7', 'transition_kernel_delete_to_delete_8', 'transition_kernel_left_flank_loop_9', 'transition_kernel_left_flank_exit_10', 'transition_kernel_unannotated_segment_loop_11', 'transition_kernel_unannotated_segment_exit_12', 'transition_kernel_end_to_unannotated_segment_15', 'transition_kernel_end_to_right_flank_16', 'transition_kernel_end_to_terminal_17', 'transition_kernel_begin_to_match_0', 'transition_kernel_match_to_end_1', 'transition_kernel_match_to_match_2', 'transition_kernel_match_to_insert_3', 'transition_kernel_insert_to_match_4', 'transition_kernel_insert_to_insert_5', 'transition_kernel_match_to_delete_6', 'transition_kernel_delete_to_match_7', 'transition_kernel_delete_to_delete_8', 'transition_kernel_left_flank_loop_9', 'transition_kernel_left_flank_exit_10', 'transition_kernel_unannotated_segment_loop_11', 'transition_kernel_unannotated_segment_exit_12', 'transition_kernel_end_to_unannotated_segment_15', 'transition_kernel_end_to_right_flank_16', 'transition_kernel_end_to_terminal_17', 'transition_kernel_begin_to_match_0', 'transition_kernel_match_to_end_1', 'transition_kernel_match_to_match_2', 'transition_kernel_match_to_insert_3', 'transition_kernel_insert_to_match_4', 'transition_kernel_insert_to_insert_5', 'transition_kernel_match_to_delete_6', 'transition_kernel_delete_to_match_7', 'transition_kernel_delete_to_delete_8', 'transition_kernel_left_flank_loop_9', 'transition_kernel_left_flank_exit_10', 'transition_kernel_unannotated_segment_loop_11', 'transition_kernel_unannotated_segment_exit_12', 'transition_kernel_end_to_unannotated_segment_15', 'transition_kernel_end_to_right_flank_16', 'transition_kernel_end_to_terminal_17', 'transition_kernel_begin_to_match_0', 'transition_kernel_match_to_end_1', 'transition_kernel_match_to_match_2', 'transition_kernel_match_to_insert_3', 'transition_kernel_insert_to_match_4', 'transition_kernel_insert_to_insert_5', 'transition_kernel_match_to_delete_6', 'transition_kernel_delete_to_match_7', 'transition_kernel_delete_to_delete_8', 'transition_kernel_left_flank_loop_9', 'transition_kernel_left_flank_exit_10', 'transition_kernel_unannotated_segment_loop_11', 'transition_kernel_unannotated_segment_exit_12', 'transition_kernel_end_to_unannotated_segment_15', 'transition_kernel_end_to_right_flank_16', 'transition_kernel_end_to_terminal_17', 'init_logit_0', 'init_logit_1', 'init_logit_2', 'init_logit_3'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 - 23s - 1s/step - loss: 111.8107\n",
      "Epoch 2/10\n",
      "17/17 - 4s - 246ms/step - loss: 78.9714\n",
      "Epoch 3/10\n",
      "17/17 - 4s - 248ms/step - loss: 71.0773\n",
      "Epoch 4/10\n",
      "17/17 - 4s - 242ms/step - loss: 69.2390\n",
      "Epoch 5/10\n",
      "17/17 - 4s - 249ms/step - loss: 68.7375\n",
      "Epoch 6/10\n",
      "17/17 - 4s - 245ms/step - loss: 68.5549\n",
      "Epoch 7/10\n",
      "17/17 - 4s - 234ms/step - loss: 68.3607\n",
      "Epoch 8/10\n",
      "17/17 - 4s - 244ms/step - loss: 68.3971\n"
     ]
    }
   ],
   "source": [
    "out_filename = \"test/data/interactive.alignment.fasta\"\n",
    "config = Configuration.make_default(num_models)\n",
    "with SequenceDataset(train_filename, fmt=\"fasta\") as data:\n",
    "    alignment_model = Align.run_learnMSA(data,\n",
    "                                        out_filename,\n",
    "                                        config, \n",
    "                                        sequence_weights=Align.compute_sequence_weights(train_filename, \"tmp\") if use_weights else None,\n",
    "                                        verbose=True,\n",
    "                                        align_insertions=align_insertions)\n",
    "    Visualize.print_and_plot(alignment_model, alignment_model.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d38f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "488d3aa71b322ef168bf72fc4d82bebaa59a8882dc4050bd9af49d22feb8fb8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

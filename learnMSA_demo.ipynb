{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f067659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 11:33:21.850627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-07 11:33:21.867456: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-07 11:33:21.872577: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741343603.261837 1182680 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741343603.299740 1182680 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741343603.299991 1182680 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741343603.302998 1182680 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741343603.303191 1182680 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741343603.303356 1182680 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741343603.383382 1182680 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741343603.383602 1182680 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1741343603.383782 1182680 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' #omit info \n",
    "from learnMSA.msa_hmm import Configuration, Align, Visualize, Clustering\n",
    "from learnMSA.msa_hmm.SequenceDataset import SequenceDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c715bf4-a1bb-40b3-95bf-67a61b1916fa",
   "metadata": {},
   "source": [
    "## learnMSA demo\n",
    "\n",
    "In this notebook, we will fit a number of HMM models to a dataset of unaligned sequences. \n",
    "We will then use the fitted models to align the sequences and compare the results.\n",
    "Moreover, we will visualize the best (according to an objective criterion) model and alignment.\n",
    "\n",
    "*This notebook is meant to be a demo for running learnMSA in Python code. Check the readme if you want to run learnMSA from the command line.* \n",
    "\n",
    "Change the variables in the following cell to fit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59efc747-cd9a-47bc-a38c-ad654566b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fasta file with unaligned sequences.\n",
    "\n",
    "train_filename = \"test/data/egf.fasta\"\n",
    "\n",
    "# Reference file with aligned sequences that have matching IDs to (potentially a subset of) the \n",
    "# sequences in the train_file.\n",
    "# Replace with empty string if no reference is available.\n",
    "ref_filename = \"test/data/egf.ref\"\n",
    "\n",
    "# The number of independently trained models.\n",
    "num_models = 10\n",
    "\n",
    "# Use sequence weights based on a rapid pre-clustering of the sequences (requires mmseqs2 to be installed)\n",
    "use_weights = True\n",
    "\n",
    "# Align long insertions with an external aligner left unaligned by the main MSA stage (requires famsa to be installed).\n",
    "align_insertions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e9512-4a21-4288-b94f-863012b5ec52",
   "metadata": {},
   "source": [
    "## Run learnMSA from Python (Training + Viterbi alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3fa850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of 10 models on file egf.fasta\n",
      "Configuration: \n",
      "{\n",
      "num_models : 10\n",
      "transitioner : ProfileHMMTransitioner(\n",
      " transition_init=\n",
      "    {\n",
      "    begin_to_match : DefaultEntry() , match_to_end : DefaultExit() , \n",
      "    match_to_match : DefaultMatchTransition(1) , match_to_insert : DefaultMatchTransition(-1) , \n",
      "    insert_to_match : Norm(0, 0.1) , insert_to_insert : Norm(-0.5, 0.1) , \n",
      "    match_to_delete : DefaultMatchTransition(-1) , delete_to_match : Norm(0, 0.1) , \n",
      "    delete_to_delete : Norm(-0.5, 0.1) , left_flank_loop : Norm(0, 0.1) , \n",
      "    left_flank_exit : Norm(-1, 0.1) , right_flank_loop : Norm(0, 0.1) , \n",
      "    right_flank_exit : Norm(-1, 0.1) , unannotated_segment_loop : Norm(0, 0.1) , \n",
      "    unannotated_segment_exit : Norm(-1, 0.1) , end_to_unannotated_segment : Norm(-9, 0.1) , \n",
      "    end_to_right_flank : Norm(0, 0.1) , end_to_terminal : Norm(0, 0.1)\n",
      "    },\n",
      " flank_init=Const(0.0),\n",
      " prior=ProfileHMMTransitionPrior(match_comp=1, insert_comp=1, delete_comp=1, alpha_flank=7000, alpha_single=1000000000.0, alpha_global=10000.0, alpha_flank_compl=1, alpha_single_compl=1, alpha_global_compl=1),\n",
      " frozen_kernels={})\n",
      "emitter : ProfileHMMEmitter(\n",
      " emission_init=EmissionInitializer(),\n",
      " insertion_init=Const(shape=(23,)),\n",
      " prior=AminoAcidPrior(comp_count=1),\n",
      " frozen_insertions=True, )\n",
      "max_surgery_runs : 2\n",
      "length_init_quantile : 0.5\n",
      "surgery_quantile : 0.5\n",
      "min_surgery_seqs : 100000.0\n",
      "len_mul : 0.8\n",
      "batch_size : functools.partial(<function get_adaptive_batch_size at 0x7547583977e0>, small_gpu=True)\n",
      "learning_rate : 0.1\n",
      "epochs : [10, 2, 10]\n",
      "crop_long_seqs : 65\n",
      "use_prior : True\n",
      "dirichlet_mix_comp_count : 1\n",
      "use_anc_probs : True\n",
      "trainable_rate_matrices : False\n",
      "trainable_distances : True\n",
      "surgery_del : 0.5\n",
      "surgery_ins : 0.5\n",
      "encoder_initializer : [Const(-3.0), Const(shape=(10, 20, 20)), Const(shape=(10, 20))]\n",
      "model_criterion : AIC\n",
      "encoder_weight_extractor : None\n",
      "experimental_evolve_upper_half : False\n",
      "cluster_seq_id : 0.9\n",
      "use_language_model : False\n",
      "frozen_insertions : True\n",
      "allow_user_keys_in_config : False\n",
      "}\n",
      "Fitting models of lengths [24 29 24 24 26 27 27 24 25 24] on 7774 sequences.\n",
      "Batch size= 256 Learning rate= 0.1\n",
      "Using sequence weights  [1.         1.         1.         ... 0.33333334 0.14285715 0.5       ] .\n",
      "1 sequences are longer than 65 and will be cropped for training.\n",
      "To disable cropping, use --crop disable. To change the cropping limit to X, use --crop X.\n",
      "Using 1 GPUs.\n",
      "Epoch 1/10\n",
      "34/34 - 52s - 2s/step - loss: 84.8572 - loglik: -7.9678e+01 - prior: -5.1796e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "34/34 - 11s - 325ms/step - loss: 63.4948 - loglik: -6.1605e+01 - prior: -1.8893e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "34/34 - 11s - 328ms/step - loss: 62.3735 - loglik: -6.0652e+01 - prior: -1.7218e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "34/34 - 11s - 326ms/step - loss: 62.0061 - loglik: -6.0324e+01 - prior: -1.6816e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "34/34 - 11s - 333ms/step - loss: 61.9415 - loglik: -6.0287e+01 - prior: -1.6549e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "34/34 - 11s - 326ms/step - loss: 61.8531 - loglik: -6.0210e+01 - prior: -1.6433e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "34/34 - 11s - 332ms/step - loss: 61.7471 - loglik: -6.0112e+01 - prior: -1.6352e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "34/34 - 11s - 327ms/step - loss: 61.7236 - loglik: -6.0101e+01 - prior: -1.6229e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "34/34 - 11s - 333ms/step - loss: 61.6970 - loglik: -6.0082e+01 - prior: -1.6147e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "34/34 - 11s - 333ms/step - loss: 61.6615 - loglik: -6.0048e+01 - prior: -1.6131e+00 - aux_loss: 0.0000e+00\n",
      "Fitted model successfully.\n",
      "Creating alignment model...\n",
      "Successfully created alignment model.\n",
      "expansions model 0: [(12, 2), (13, 3), (14, 1), (15, 1), (16, 1), (17, 2)]\n",
      "discards model 0: []\n",
      "expansions model 1: [(12, 2), (14, 2)]\n",
      "discards model 1: []\n",
      "expansions model 2: [(12, 2), (13, 3), (14, 2), (15, 1), (16, 1), (18, 2)]\n",
      "discards model 2: []\n",
      "expansions model 3: [(12, 3), (13, 4), (16, 1), (17, 2)]\n",
      "discards model 3: []\n",
      "expansions model 4: [(12, 2), (13, 3), (18, 1), (19, 2)]\n",
      "discards model 4: []\n",
      "expansions model 5: [(12, 2), (13, 2), (19, 2), (20, 2)]\n",
      "discards model 5: []\n",
      "expansions model 6: [(12, 2), (13, 2), (15, 2), (16, 1)]\n",
      "discards model 6: []\n",
      "expansions model 7: [(12, 3), (13, 4), (16, 1), (18, 2)]\n",
      "discards model 7: []\n",
      "expansions model 8: [(12, 2), (13, 3), (14, 1), (17, 1), (18, 2)]\n",
      "discards model 8: []\n",
      "expansions model 9: [(12, 2), (13, 3), (14, 1), (15, 1), (16, 1), (17, 2)]\n",
      "discards model 9: []\n",
      "Re-initialized the encoder parameters.\n",
      "Fitting models of lengths [34, 33, 35, 34, 34, 35, 34, 34, 34, 34] on 7774 sequences.\n",
      "Batch size= 256 Learning rate= 0.1\n",
      "Using sequence weights  [1.         1.         1.         ... 0.33333334 0.14285715 0.5       ] .\n",
      "1 sequences are longer than 65 and will be cropped for training.\n",
      "To disable cropping, use --crop disable. To change the cropping limit to X, use --crop X.\n",
      "Using 1 GPUs.\n",
      "Epoch 1/10\n",
      "34/34 - 51s - 2s/step - loss: 63.4995 - loglik: -5.8583e+01 - prior: -4.9161e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "34/34 - 11s - 337ms/step - loss: 58.7325 - loglik: -5.7003e+01 - prior: -1.7300e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "34/34 - 11s - 332ms/step - loss: 58.4349 - loglik: -5.6923e+01 - prior: -1.5114e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "34/34 - 11s - 336ms/step - loss: 58.3311 - loglik: -5.6861e+01 - prior: -1.4701e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "34/34 - 11s - 323ms/step - loss: 58.2910 - loglik: -5.6864e+01 - prior: -1.4273e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "34/34 - 11s - 335ms/step - loss: 58.1876 - loglik: -5.6792e+01 - prior: -1.3955e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "34/34 - 12s - 338ms/step - loss: 58.1701 - loglik: -5.6803e+01 - prior: -1.3668e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "34/34 - 12s - 342ms/step - loss: 58.1467 - loglik: -5.6808e+01 - prior: -1.3384e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "34/34 - 11s - 336ms/step - loss: 58.0831 - loglik: -5.6761e+01 - prior: -1.3220e+00 - aux_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "34/34 - 11s - 335ms/step - loss: 58.0578 - loglik: -5.6751e+01 - prior: -1.3063e+00 - aux_loss: 0.0000e+00\n",
      "Fitted model successfully.\n",
      "Creating alignment model...\n",
      "Successfully created alignment model.\n",
      "Time for alignment: 343.6660\n",
      "Likelihoods:  ['-56.8889', '-56.9134', '-56.8456', '-56.8768', '-56.8949', '-56.9380', '-56.8773', '-56.8557', '-56.9030', '-56.9305']\n",
      "Mean likelihood:  -56.89240901663398\n",
      "Selection criterion: AIC\n",
      "Best model:  2 (0-based)\n",
      "Aligning 2 insertion slices with famsa.\n",
      "time for generating output: 9.1116\n",
      "Wrote file test/data/interactive.alignment.fasta\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 324ms/step\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 2 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      4\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrop_long_seqs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(data\u001b[38;5;241m.\u001b[39mseq_lens))) \u001b[38;5;66;03m#comment out to disable cropping\u001b[39;00m\n\u001b[1;32m      5\u001b[0m alignment_model \u001b[38;5;241m=\u001b[39m Align\u001b[38;5;241m.\u001b[39mrun_learnMSA(data,\n\u001b[1;32m      6\u001b[0m                                     out_filename,\n\u001b[1;32m      7\u001b[0m                                     config, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                                     align_insertions\u001b[38;5;241m=\u001b[39malign_insertions)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mVisualize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43malignment_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malignment_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/learnMSA/learnMSA/msa_hmm/Visualize.py:306\u001b[0m, in \u001b[0;36mprint_and_plot\u001b[0;34m(am, model_index, max_seq, seqs_to_plot, path_colors, path_width, edge_label_pos, seq_ids, show_model, show_anc_probs, show_logo, model_filename, anc_probs_filename, logo_filename)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(msa[:max_seq]):\n\u001b[1;32m    305\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[am\u001b[38;5;241m.\u001b[39mindices[i]]\u001b[38;5;241m*\u001b[39mam\u001b[38;5;241m.\u001b[39mmsa_hmm_layer\u001b[38;5;241m.\u001b[39mcell\u001b[38;5;241m.\u001b[39mnum_models])\n\u001b[0;32m--> 306\u001b[0m     tau \u001b[38;5;241m=\u001b[39m \u001b[43mam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manc_probs_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_times\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    307\u001b[0m     param_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml=\u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (ll[i]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_t=\u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m tau[am\u001b[38;5;241m.\u001b[39mindices[i]]\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m seq_ids:\n",
      "File \u001b[0;32m~/miniforge3/envs/learnMSAdev/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/learnMSAdev/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 2 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "out_filename = \"test/data/interactive.alignment.fasta\"\n",
    "config = Configuration.make_default(num_models)\n",
    "with SequenceDataset(train_filename, fmt=\"fasta\") as data:\n",
    "    config[\"crop_long_seqs\"] = int(np.ceil(2 * np.mean(data.seq_lens))) #comment out to disable cropping\n",
    "    alignment_model = Align.run_learnMSA(data,\n",
    "                                        out_filename,\n",
    "                                        config, \n",
    "                                        sequence_weights=Clustering.compute_sequence_weights(train_filename, \"tmp\", config[\"cluster_seq_id\"]) \n",
    "                                            if use_weights else None,\n",
    "                                        verbose=True,\n",
    "                                        align_insertions=align_insertions)\n",
    "    Visualize.print_and_plot(alignment_model, alignment_model.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3d38f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE: 1ixa\n",
      "HERE: 1apo\n",
      "HERE: 1urk\n",
      "HERE: 1fsb\n",
      "HERE: 1esl\n",
      "HERE: 1hre\n",
      "HERE: 1epi\n",
      "HERE: 4tgf\n",
      "HERE: 1hcgb\n",
      "HERE: 1dan1\n",
      "HERE: 1dan2\n",
      "HERE: 1rfnb\n"
     ]
    }
   ],
   "source": [
    "!id_list=$(sed -n '/^>/p' {ref_filename} | sed 's/^.//') ; export MAX_N_PID_4_TCOFFEE=10000000 ; t_coffee -other_pg seq_reformat -in test/data/interactive.alignment.fasta -action +extract_seq_list ${{id_list[@]}} +rm_gap > test/data/interactive.projection.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c4c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "seq1       seq2          Sim   [ALL]           Tot  \n",
      "egf           12         31.1    73.6 [100.0]   [ 5182]\n"
     ]
    }
   ],
   "source": [
    "!t_coffee -other_pg aln_compare -al1 {ref_filename} -al2 test/data/interactive.projection.fasta -compare_mode sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9df13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t-coffee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

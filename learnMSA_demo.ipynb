{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9ab05b-4bf0-48d3-bf1c-7c27050852f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!mamba install t-coffee mmseqs2 -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f067659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 09:19:00.680931: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 09:19:00.753161: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-04 09:19:00.767820: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 09:19:01.120572: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/beckerf/mambaforge/envs/learnMSAdev/lib/:/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2023-12-04 09:19:01.120867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/beckerf/mambaforge/envs/learnMSAdev/lib/:/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2023-12-04 09:19:01.120871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-12-04 09:19:01.843459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:01.856896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:01.857059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:01.857474: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 09:19:01.858565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:01.858674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:01.858758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:02.126587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:02.126734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:02.126828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:02.126915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 323 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from learnMSA.msa_hmm import Configuration, Align, Visualize\n",
    "from learnMSA.msa_hmm.SequenceDataset import SequenceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c715bf4-a1bb-40b3-95bf-67a61b1916fa",
   "metadata": {},
   "source": [
    "## learnMSA demo\n",
    "\n",
    "In this notebook, we will fit a number of HMM models to a dataset of unaligned sequences. \n",
    "We will then use the fitted models to align the sequences and compare the results.\n",
    "Moreover, we will visualize the best (according to an objective criterion) model and alignment.\n",
    "\n",
    "*This notebook is meant to be a demo for running learnMSA in Python code. Check the readme if you want to run learnMSA from the command line.* \n",
    "\n",
    "Change the variables in the following cell to fit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59efc747-cd9a-47bc-a38c-ad654566b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fasta file with unaligned sequences.\n",
    "\n",
    "train_filename = \"test/data/rhv.fasta\"\n",
    "\n",
    "# Reference file with aligned sequences that have matching IDs to (potentially a subset of) the \n",
    "# sequences in the train_file.\n",
    "# Replace with empty string if no reference is available.\n",
    "ref_filename = \"test/data/rhv.ref\"\n",
    "\n",
    "# The number of independently trained models.\n",
    "num_models = 2\n",
    "\n",
    "# Use sequence weights based on a rapid pre-clustering of the sequences (requires mmseqs2 to be installed)\n",
    "use_weights = True\n",
    "\n",
    "# Align long insertions with an external aligner left unaligned by the main MSA stage (requires famsa to be installed).\n",
    "align_insertions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e9512-4a21-4288-b94f-863012b5ec52",
   "metadata": {},
   "source": [
    "## Run learnMSA from Python (Training + Viterbi alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a47ebb-cc04-4303-9194-6df7d9fe7bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of 2 models on file egf.fasta\n",
      "Configuration: \n",
      "{\n",
      "num_models : 2\n",
      "transitioner : ProfileHMMTransitioner(\n",
      " transition_init=\n",
      "    {\n",
      "    begin_to_match : DefaultEntry() , match_to_end : DefaultExit() , \n",
      "    match_to_match : DefaultMatchTransition(1) , match_to_insert : DefaultMatchTransition(-1) , \n",
      "    insert_to_match : Norm(0, 0.1) , insert_to_insert : Norm(-0.5, 0.1) , \n",
      "    match_to_delete : DefaultMatchTransition(-1) , delete_to_match : Norm(0, 0.1) , \n",
      "    delete_to_delete : Norm(-0.5, 0.1) , left_flank_loop : Norm(0, 0.1) , \n",
      "    left_flank_exit : Norm(-1, 0.1) , right_flank_loop : Norm(0, 0.1) , \n",
      "    right_flank_exit : Norm(-1, 0.1) , unannotated_segment_loop : Norm(0, 0.1) , \n",
      "    unannotated_segment_exit : Norm(-1, 0.1) , end_to_unannotated_segment : Norm(-9, 0.1) , \n",
      "    end_to_right_flank : Norm(0, 0.1) , end_to_terminal : Norm(0, 0.1)\n",
      "    },\n",
      " flank_init=Const(0.0),\n",
      " prior=ProfileHMMTransitionPrior(match_comp=1, insert_comp=1, delete_comp=1, alpha_flank=7000, alpha_single=1000000000.0, alpha_global=10000.0, alpha_flank_compl=1, alpha_single_compl=1, alpha_global_compl=1),\n",
      " frozen_kernels={})\n",
      "emitter : ProfileHMMEmitter(\n",
      " emission_init=DefaultEmission(),\n",
      " insertion_init=Const(shape=(23,)),\n",
      " prior=AminoAcidPrior(comp_count=1),\n",
      " frozen_insertions=True, )\n",
      "max_surgery_runs : 4\n",
      "length_init_quantile : 0.5\n",
      "surgery_quantile : 0.5\n",
      "min_surgery_seqs : 100000.0\n",
      "len_mul : 0.8\n",
      "batch_size : <function get_adaptive_batch_size at 0x7f21e86a7910>\n",
      "learning_rate : 0.1\n",
      "epochs : [10, 2, 10]\n",
      "use_prior : True\n",
      "dirichlet_mix_comp_count : 1\n",
      "use_anc_probs : True\n",
      "trainable_rate_matrices : False\n",
      "surgery_del : 0.5\n",
      "surgery_ins : 0.5\n",
      "num_rate_matrices : 1\n",
      "per_matrix_rate : False\n",
      "matrix_rate_l2 : 0.0\n",
      "shared_rate_matrix : False\n",
      "equilibrium_sample : False\n",
      "transposed : False\n",
      "encoder_initializer : [Const(-3), Const(shape=(2, 20, 20)), Const(shape=(2, 20))]\n",
      "model_criterion : AIC\n",
      "encoder_weight_extractor : None\n",
      "experimental_evolve_upper_half : False\n",
      "cluster_seq_id : 0.9\n",
      "use_language_model : False\n",
      "frozen_insertions : True\n",
      "allow_user_keys_in_config : False\n",
      "}\n",
      "Fitting models of lengths [25 27] on 7774 sequences.\n",
      "Batch size= 512 Learning rate= 0.1\n",
      "Using sequence weights  [1.         0.33333334 0.07692308 ... 0.04347826 0.02777778 0.25      ] .\n",
      "Using 1 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 09:19:09.927673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:09.927828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:09.927912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:09.928034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:09.928124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:09.928191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 323 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 09:19:10.992620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:10.992766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:10.992856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:10.992968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:10.993060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:10.993128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 323 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-12-04 09:19:12.472360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:12.472531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:12.472617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:12.472736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:12.472820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 09:19:12.472888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 323 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-12-04 09:19:14.493955: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2023-12-04 09:19:14.493990: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-12-04 09:19:14.494011: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at matmul_op_impl.h:627 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-12-04 09:19:14.499350: E tensorflow/stream_executor/cuda/cuda_blas.cc:218] failed to create cublas handle: cublas error\n",
      "2023-12-04 09:19:14.499364: E tensorflow/stream_executor/cuda/cuda_blas.cc:220] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-12-04 09:19:14.499370: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at matmul_op_impl.h:627 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_4/anc_probs_layer/matrix_exponential/MatMul' defined at (most recent call last):\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_151146/1985174582.py\", line 4, in <module>\n      alignment_model = Align.run_learnMSA(data,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py\", line 155, in run_learnMSA\n      am = fit_and_align(data,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py\", line 87, in fit_and_align\n      model, history = train.fit_model(model_generator,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Training.py\", line 361, in fit_model\n      history = model.fit(dataset,\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/AncProbsLayer.py\", line 243, in call\n      anc_probs = make_anc_probs(only_std_aa_inputs,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/AncProbsLayer.py\", line 76, in make_anc_probs\n      P = tf.linalg.expm(tauQ) # P[m,b,k,i,j] = P(X(tau_b) = j | X(0) = i; Q_k, model m))\nNode: 'model_4/anc_probs_layer/matrix_exponential/MatMul'\nDetected at node 'model_4/anc_probs_layer/matrix_exponential/MatMul' defined at (most recent call last):\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_151146/1985174582.py\", line 4, in <module>\n      alignment_model = Align.run_learnMSA(data,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py\", line 155, in run_learnMSA\n      am = fit_and_align(data,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py\", line 87, in fit_and_align\n      model, history = train.fit_model(model_generator,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Training.py\", line 361, in fit_model\n      history = model.fit(dataset,\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/AncProbsLayer.py\", line 243, in call\n      anc_probs = make_anc_probs(only_std_aa_inputs,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/AncProbsLayer.py\", line 76, in make_anc_probs\n      P = tf.linalg.expm(tauQ) # P[m,b,k,i,j] = P(X(tau_b) = j | X(0) = i; Q_k, model m))\nNode: 'model_4/anc_probs_layer/matrix_exponential/MatMul'\n2 root error(s) found.\n  (0) INTERNAL:  Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_4/anc_probs_layer/matrix_exponential/MatMul}}]]\n\t [[gradient_tape/model_4/msa_hmm_layer/A/mul/_186]]\n  (1) INTERNAL:  Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_4/anc_probs_layer/matrix_exponential/MatMul}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_22577]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m config \u001b[39m=\u001b[39m Configuration\u001b[39m.\u001b[39mmake_default(num_models)\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m SequenceDataset(train_filename, fmt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfasta\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m data:\n\u001b[0;32m----> 4\u001b[0m     alignment_model \u001b[39m=\u001b[39m Align\u001b[39m.\u001b[39;49mrun_learnMSA(data,\n\u001b[1;32m      5\u001b[0m                                         out_filename,\n\u001b[1;32m      6\u001b[0m                                         config, \n\u001b[1;32m      7\u001b[0m                                         sequence_weights\u001b[39m=\u001b[39;49mAlign\u001b[39m.\u001b[39;49mcompute_sequence_weights(train_filename, \u001b[39m\"\u001b[39;49m\u001b[39mtmp\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mif\u001b[39;49;00m use_weights \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      8\u001b[0m                                         verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      9\u001b[0m                                         align_insertions\u001b[39m=\u001b[39;49malign_insertions)\n\u001b[1;32m     10\u001b[0m     Visualize\u001b[39m.\u001b[39mprint_and_plot(alignment_model, alignment_model\u001b[39m.\u001b[39mbest_model)\n",
      "File \u001b[0;32m~/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py:155\u001b[0m, in \u001b[0;36mrun_learnMSA\u001b[0;34m(data, out_filename, config, model_generator, batch_generator, subset_ids, align_insertions, insertion_aligner, aligner_threads, sequence_weights, verbose, initial_model_length_callback, select_best_for_comparison)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     t_a \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 155\u001b[0m     am \u001b[39m=\u001b[39m fit_and_align(data, \n\u001b[1;32m    156\u001b[0m                         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    157\u001b[0m                         model_generator\u001b[39m=\u001b[39;49mmodel_generator,\n\u001b[1;32m    158\u001b[0m                         batch_generator\u001b[39m=\u001b[39;49mbatch_generator,\n\u001b[1;32m    159\u001b[0m                         subset\u001b[39m=\u001b[39;49msubset, \n\u001b[1;32m    160\u001b[0m                         initial_model_length_callback\u001b[39m=\u001b[39;49minitial_model_length_callback,\n\u001b[1;32m    161\u001b[0m                         sequence_weights\u001b[39m=\u001b[39;49msequence_weights,\n\u001b[1;32m    162\u001b[0m                         verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m    164\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTime for alignment:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mt_a))\n",
      "File \u001b[0;32m~/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py:87\u001b[0m, in \u001b[0;36mfit_and_align\u001b[0;34m(data, config, model_generator, batch_generator, subset, initial_model_length_callback, sequence_weights, verbose)\u001b[0m\n\u001b[1;32m     85\u001b[0m     decode_indices \u001b[39m=\u001b[39m full_length_estimate\n\u001b[1;32m     86\u001b[0m epochs_this_iteration \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m i\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m last_iteration \u001b[39melse\u001b[39;00m \u001b[39m2\u001b[39m]\n\u001b[0;32m---> 87\u001b[0m model, history \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39;49mfit_model(model_generator,\n\u001b[1;32m     88\u001b[0m                                   batch_generator,\n\u001b[1;32m     89\u001b[0m                                   data,\n\u001b[1;32m     90\u001b[0m                                   train_indices,\n\u001b[1;32m     91\u001b[0m                                   model_lengths, \n\u001b[1;32m     92\u001b[0m                                   config,\n\u001b[1;32m     93\u001b[0m                                   batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m     94\u001b[0m                                   epochs\u001b[39m=\u001b[39;49mepochs_this_iteration,\n\u001b[1;32m     95\u001b[0m                                   sequence_weights\u001b[39m=\u001b[39;49msequence_weights,\n\u001b[1;32m     96\u001b[0m                                   verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     97\u001b[0m am \u001b[39m=\u001b[39m AlignmentModel(data, batch_generator, decode_indices, batch_size\u001b[39m=\u001b[39mbatch_size, model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m last_iteration:\n",
      "File \u001b[0;32m~/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Training.py:361\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(model_generator, batch_generator, data, indices, model_lengths, config, batch_size, epochs, sequence_weights, verbose)\u001b[0m\n\u001b[1;32m    358\u001b[0m             msa_hmm_layer\u001b[39m.\u001b[39mreverse_cell\u001b[39m.\u001b[39memitter[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstep_counter\u001b[39m.\u001b[39massign_add(\u001b[39m1.\u001b[39m)\n\u001b[1;32m    359\u001b[0m     \u001b[39m#callbacks.append(CustomCallback())\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset, \n\u001b[1;32m    362\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    363\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m    364\u001b[0m                       callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    365\u001b[0m                     verbose \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mint\u001b[39;49m(verbose))\n\u001b[1;32m    366\u001b[0m tf\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39msetLevel(\u001b[39m'\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'model_4/anc_probs_layer/matrix_exponential/MatMul' defined at (most recent call last):\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_151146/1985174582.py\", line 4, in <module>\n      alignment_model = Align.run_learnMSA(data,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py\", line 155, in run_learnMSA\n      am = fit_and_align(data,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py\", line 87, in fit_and_align\n      model, history = train.fit_model(model_generator,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Training.py\", line 361, in fit_model\n      history = model.fit(dataset,\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/AncProbsLayer.py\", line 243, in call\n      anc_probs = make_anc_probs(only_std_aa_inputs,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/AncProbsLayer.py\", line 76, in make_anc_probs\n      P = tf.linalg.expm(tauQ) # P[m,b,k,i,j] = P(X(tau_b) = j | X(0) = i; Q_k, model m))\nNode: 'model_4/anc_probs_layer/matrix_exponential/MatMul'\nDetected at node 'model_4/anc_probs_layer/matrix_exponential/MatMul' defined at (most recent call last):\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/beckerf/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_151146/1985174582.py\", line 4, in <module>\n      alignment_model = Align.run_learnMSA(data,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py\", line 155, in run_learnMSA\n      am = fit_and_align(data,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py\", line 87, in fit_and_align\n      model, history = train.fit_model(model_generator,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Training.py\", line 361, in fit_model\n      history = model.fit(dataset,\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/AncProbsLayer.py\", line 243, in call\n      anc_probs = make_anc_probs(only_std_aa_inputs,\n    File \"/home/beckerf/brain/tmp_work/learnMSA/learnMSA/msa_hmm/AncProbsLayer.py\", line 76, in make_anc_probs\n      P = tf.linalg.expm(tauQ) # P[m,b,k,i,j] = P(X(tau_b) = j | X(0) = i; Q_k, model m))\nNode: 'model_4/anc_probs_layer/matrix_exponential/MatMul'\n2 root error(s) found.\n  (0) INTERNAL:  Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_4/anc_probs_layer/matrix_exponential/MatMul}}]]\n\t [[gradient_tape/model_4/msa_hmm_layer/A/mul/_186]]\n  (1) INTERNAL:  Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_4/anc_probs_layer/matrix_exponential/MatMul}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_22577]"
     ]
    }
   ],
   "source": [
    "out_filename = \"test/data/interactive.alignment.fasta\"\n",
    "config = Configuration.make_default(num_models)\n",
    "with SequenceDataset(train_filename, fmt=\"fasta\") as data:\n",
    "    alignment_model = Align.run_learnMSA(data,\n",
    "                                        out_filename,\n",
    "                                        config, \n",
    "                                        sequence_weights=Align.compute_sequence_weights(train_filename, \"tmp\") if use_weights else None,\n",
    "                                        verbose=True,\n",
    "                                        align_insertions=align_insertions)\n",
    "    Visualize.print_and_plot(alignment_model, alignment_model.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceefb9fa-1d18-48d1-991d-12bce94a7529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE: 1tme\n",
      "HERE: 2mev\n",
      "HERE: 1bbt\n",
      "HERE: 1r1a\n",
      "HERE: 4rhv\n",
      "HERE: 2plv\n"
     ]
    }
   ],
   "source": [
    "!id_list=$(sed -n '/^>/p' {ref_filename} | sed 's/^.//') ; export MAX_N_PID_4_TCOFFEE=10000000 ; t_coffee -other_pg seq_reformat -in rhv.out -action +extract_seq_list ${{id_list[@]}} +rm_gap > test/data/interactive.projection.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb89f14-dd1f-4b28-8869-59ebc41a1778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "seq1       seq2          Sim   [ALL]           Tot  \n",
      "rhv           6          33.1    24.1 [100.0]   [20998]\n"
     ]
    }
   ],
   "source": [
    "!t_coffee -other_pg aln_compare -al1 {ref_filename} -al2 test/data/interactive.projection.fasta -compare_mode sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5840b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "488d3aa71b322ef168bf72fc4d82bebaa59a8882dc4050bd9af49d22feb8fb8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

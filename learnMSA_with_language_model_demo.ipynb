{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb62c54-8f80-4130-9721-2bf5290f6500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 21:51:36.408614: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' #omit info \n",
    "from learnMSA.msa_hmm import Configuration, Align, Visualize, Emitter, Transitioner, Initializers, Training\n",
    "from learnMSA.msa_hmm.SequenceDataset import SequenceDataset\n",
    "from learnMSA.protein_language_models import Common, EmbeddingBatchGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e4cf6",
   "metadata": {},
   "source": [
    "\n",
    "# Experimental demo: learnMSA + protein language model\n",
    "\n",
    "This notebook demonstrates how to align a set of protein sequences with learnMSA supported by a large, pre-trained protein language model.\n",
    "\n",
    "This configuration of learnMSA - although a prototype - is the most accurate variant of learnMSA currently available. It is also the most computationally expensive. It is recommended to run this notebook on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ddeab2-cb0e-4d42-8992-8cf5f78017d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fasta file with unaligned sequences.\n",
    "\n",
    "train_filename = \"test/data/egf.fasta\"\n",
    "\n",
    "# Reference file with aligned sequences that have matching IDs to (potentially a subset of) the \n",
    "# sequences in the train_file.\n",
    "# Replace with empty string if no reference is available.\n",
    "ref_filename = \"test/data/egf.ref\"\n",
    "\n",
    "# The number of independently trained models.\n",
    "num_models = 4\n",
    "\n",
    "# Use sequence weights based on a rapid pre-clustering of the sequences (requires mmseqs2 to be installed)\n",
    "use_weights = True\n",
    "\n",
    "# Align long insertions with an external aligner left unaligned by the main MSA stage (requires famsa to be installed).\n",
    "align_insertions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44f1d1",
   "metadata": {},
   "source": [
    "HMM training supported by protein embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cebcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(filename, out_filename):\n",
    "    scoring_model_config = Common.ScoringModelConfig()\n",
    "    config = Configuration.make_default(num_models, \n",
    "                                        use_language_model=True, \n",
    "                                        scoring_model_config=scoring_model_config,\n",
    "                                        frozen_insertions=True,\n",
    "                                        num_prior_components=10,\n",
    "                                        V2_emitter=True,\n",
    "                                        V2_temperature=3.)\n",
    "    config[\"batch_size\"] = 3000\n",
    "    # we have to define a special model- and batch generator if using a language model\n",
    "    # because the emission probabilities are computed differently and the LM requires specific inputs\n",
    "    model_gen = EmbeddingBatchGenerator.make_generic_embedding_model_generator(config[\"scoring_model_config\"].dim)\n",
    "    batch_gen = EmbeddingBatchGenerator.EmbeddingBatchGenerator(config[\"scoring_model_config\"])\n",
    "    with SequenceDataset(train_filename, fmt=\"fasta\") as data:\n",
    "        config[\"crop_long_seqs\"] = int(np.ceil(3 * np.mean(data.seq_lens))) #comment out to disable cropping\n",
    "        alignment_model = Align.run_learnMSA(data,\n",
    "                                            out_filename,\n",
    "                                            config, \n",
    "                                            model_generator=model_gen,\n",
    "                                            batch_generator=batch_gen,\n",
    "                                            sequence_weights=Align.compute_sequence_weights(train_filename, \"tmp\", config[\"cluster_seq_id\"]),\n",
    "                                            verbose=True,\n",
    "                                            align_insertions=True)\n",
    "    return alignment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c2722a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m alignment_model \u001b[39m=\u001b[39m align(train_filename, \u001b[39m\"\u001b[39;49m\u001b[39mtest/data/interactive.alignment.fasta\u001b[39;49m\u001b[39m\"\u001b[39;49m) \n\u001b[1;32m      2\u001b[0m Visualize\u001b[39m.\u001b[39mprint_and_plot(alignment_model, alignment_model\u001b[39m.\u001b[39mbest_model)\n",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m, in \u001b[0;36malign\u001b[0;34m(filename, out_filename)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mwith\u001b[39;00m SequenceDataset(train_filename, fmt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfasta\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m data:\n\u001b[1;32m     16\u001b[0m     config[\u001b[39m\"\u001b[39m\u001b[39mcrop_long_seqs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mceil(\u001b[39m3\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmean(data\u001b[39m.\u001b[39mseq_lens))) \u001b[39m#comment out to disable cropping\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     alignment_model \u001b[39m=\u001b[39m Align\u001b[39m.\u001b[39mrun_learnMSA(data,\n\u001b[1;32m     18\u001b[0m                                         out_filename,\n\u001b[1;32m     19\u001b[0m                                         config, \n\u001b[1;32m     20\u001b[0m                                         model_generator\u001b[39m=\u001b[39mmodel_gen,\n\u001b[1;32m     21\u001b[0m                                         batch_generator\u001b[39m=\u001b[39mbatch_gen,\n\u001b[0;32m---> 22\u001b[0m                                         sequence_weights\u001b[39m=\u001b[39mAlign\u001b[39m.\u001b[39;49mcompute_sequence_weights(train_filename, \u001b[39m\"\u001b[39;49m\u001b[39mtmp\u001b[39;49m\u001b[39m\"\u001b[39;49m, config[\u001b[39m\"\u001b[39;49m\u001b[39mcluster_seq_id\u001b[39;49m\u001b[39m\"\u001b[39;49m]),\n\u001b[1;32m     23\u001b[0m                                         verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m                                         align_insertions\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m alignment_model\n",
      "File \u001b[0;32m~/brain/learnMSA/learnMSA/msa_hmm/Align.py:653\u001b[0m, in \u001b[0;36mcompute_sequence_weights\u001b[0;34m(fasta_filename, directory, cluster_seq_id, return_clusters)\u001b[0m\n\u001b[1;32m    640\u001b[0m cluster_files \u001b[39m=\u001b[39m directory\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(fasta_filename))[\u001b[39m0\u001b[39m]\n\u001b[1;32m    641\u001b[0m command \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mmmseqs\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m    642\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39measy-linclust\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m    643\u001b[0m             fasta_filename, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m--remove-tmp-files\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    652\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m-v\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 653\u001b[0m result \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mrun(command, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    654\u001b[0m clustering \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(cluster_files \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_cluster.tsv\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m, names\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mrepresentative\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    655\u001b[0m cluster_counts \u001b[39m=\u001b[39m clustering\u001b[39m.\u001b[39mgroupby(\u001b[39m\"\u001b[39m\u001b[39mrepresentative\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msize()\u001b[39m.\u001b[39mto_frame(\u001b[39m\"\u001b[39m\u001b[39mcluster_size\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mcommunicate(\u001b[39minput\u001b[39;49m, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    506\u001b[0m     \u001b[39mexcept\u001b[39;00m TimeoutExpired \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m   1147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[39m=\u001b[39m _time() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[39m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[39m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[39m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_wait(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1960\u001b[0m \u001b[39m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[39m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[39m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[39mif\u001b[39;00m pid \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mwaitpid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpid, wait_flags)\n\u001b[1;32m   1918\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[39m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[39m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[39m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alignment_model = align(train_filename, \"test/data/interactive.alignment.fasta\") \n",
    "Visualize.print_and_plot(alignment_model, alignment_model.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d788bc8a-d9a8-4b72-a67a-e68fa6a1ec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE: 1ixa\n",
      "HERE: 1apo\n",
      "HERE: 1urk\n",
      "HERE: 1fsb\n",
      "HERE: 1esl\n",
      "HERE: 1hre\n",
      "HERE: 1epi\n",
      "HERE: 4tgf\n",
      "HERE: 1hcgb\n",
      "HERE: 1dan1\n",
      "HERE: 1dan2\n",
      "HERE: 1rfnb\n"
     ]
    }
   ],
   "source": [
    "!id_list=$(sed -n '/^>/p' {ref_filename} | sed 's/^.//') ; export MAX_N_PID_4_TCOFFEE=10000000 ; t_coffee -other_pg seq_reformat -in test/data/interactive.alignment.fasta -action +extract_seq_list ${{id_list[@]}} +rm_gap > test/data/interactive.projection.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd433dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "seq1       seq2          Sim   [ALL]           Tot  \n",
      "egf           12         31.1    79.2 [100.0]   [ 5182]\n"
     ]
    }
   ],
   "source": [
    "!t_coffee -other_pg aln_compare -al1 {ref_filename} -al2 test/data/interactive.projection.fasta -compare_mode sp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "488d3aa71b322ef168bf72fc4d82bebaa59a8882dc4050bd9af49d22feb8fb8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

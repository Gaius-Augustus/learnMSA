{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ed4d5d-7804-471e-8bc6-91bd763f5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install t-coffee mmseqs2 -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb62c54-8f80-4130-9721-2bf5290f6500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:10:13.502863: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 15:10:13.571038: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 15:10:13.586046: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 15:10:13.972181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/beckerf/mambaforge/envs/learnMSAdev/lib/:/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-02-06 15:10:13.974190: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/beckerf/mambaforge/envs/learnMSAdev/lib/:/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-02-06 15:10:13.974194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-02-06 15:10:14.727433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:10:14.742061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:10:14.742216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:10:14.742625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 15:10:14.743732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:10:14.743835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:10:14.743921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:10:14.793433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:10:14.793574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:10:14.793659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:10:14.793742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from learnMSA.msa_hmm import Configuration, Align, Visualize, Emitter, Transitioner, Initializers, Training\n",
    "from learnMSA.msa_hmm.SequenceDataset import SequenceDataset\n",
    "from learnMSA.protein_language_models import Common, EmbeddingBatchGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e4cf6",
   "metadata": {},
   "source": [
    "\n",
    "# Experimental demo: learnMSA + protein language model\n",
    "\n",
    "This notebook demonstrates how to align a set of protein sequences with learnMSA supported by a large, pre-trained protein language model.\n",
    "\n",
    "This configuration of learnMSA - although a prototype - is the most accurate variant of learnMSA currently available. It is also the most computationally expensive. It is recommended to run this notebook on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ddeab2-cb0e-4d42-8992-8cf5f78017d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fasta file with unaligned sequences.\n",
    "\n",
    "#train_filename = \"test/data/egf.fasta\"\n",
    "train_filename = \"../../snakeMSA/data/homfam/train/peroxidase\"\n",
    "\n",
    "# Reference file with aligned sequences that have matching IDs to (potentially a subset of) the \n",
    "# sequences in the train_file.\n",
    "# Replace with empty string if no reference is available.\n",
    "#ref_filename = \"test/data/egf.ref\"\n",
    "ref_filename = \"../../snakeMSA/data/homfam/refs/peroxidase\"\n",
    "\n",
    "# The number of independently trained models.\n",
    "num_models = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44f1d1",
   "metadata": {},
   "source": [
    "HMM training supported by protein embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2cebcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(filename, out_filename):\n",
    "    scoring_model_config = Common.ScoringModelConfig(dim=32, lm_name=\"protT5\", activation=\"softmax\", scaled=False)\n",
    "    config = Configuration.make_default(num_models, \n",
    "                                        use_language_model=True, \n",
    "                                        scoring_model_config=scoring_model_config,\n",
    "                                        frozen_insertions=True,\n",
    "                                        num_prior_components=10,\n",
    "                                        V2_emitter=True,\n",
    "                                        V2_temperature=3.)\n",
    "    # we have to define a special model- and batch generator if using a language model\n",
    "    # because the emission probabilities are computed differently and the LM requires specific inputs\n",
    "    model_gen = EmbeddingBatchGenerator.make_generic_embedding_model_generator(config[\"scoring_model_config\"].dim)\n",
    "    batch_gen = EmbeddingBatchGenerator.EmbeddingBatchGenerator(config[\"scoring_model_config\"])\n",
    "    with SequenceDataset(train_filename, fmt=\"fasta\") as data:\n",
    "        config[\"crop_long_seqs\"] = int(np.ceil(3 * np.mean(data.seq_lens)))\n",
    "        alignment_model = Align.run_learnMSA(data,\n",
    "                                            out_filename,\n",
    "                                            config, \n",
    "                                            model_generator=model_gen,\n",
    "                                            batch_generator=batch_gen,\n",
    "                                            sequence_weights=Align.compute_sequence_weights(train_filename, \"tmp\", config[\"cluster_seq_id\"]),\n",
    "                                            verbose=True,\n",
    "                                            align_insertions=True)\n",
    "    return alignment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2722a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of 4 models on file peroxidase\n",
      "Configuration: \n",
      "{\n",
      "num_models : 4\n",
      "transitioner : ProfileHMMTransitioner(\n",
      " transition_init=\n",
      "    {\n",
      "    begin_to_match : DefaultEntry() , match_to_end : DefaultExit() , \n",
      "    match_to_match : DefaultMatchTransition(1) , match_to_insert : DefaultMatchTransition(-1) , \n",
      "    insert_to_match : Norm(0, 0.1) , insert_to_insert : Norm(-0.5, 0.1) , \n",
      "    match_to_delete : DefaultMatchTransition(-1) , delete_to_match : Norm(0, 0.1) , \n",
      "    delete_to_delete : Norm(-0.5, 0.1) , left_flank_loop : Norm(0, 0.1) , \n",
      "    left_flank_exit : Norm(-1, 0.1) , right_flank_loop : Norm(0, 0.1) , \n",
      "    right_flank_exit : Norm(-1, 0.1) , unannotated_segment_loop : Norm(0, 0.1) , \n",
      "    unannotated_segment_exit : Norm(-1, 0.1) , end_to_unannotated_segment : Norm(-9, 0.1) , \n",
      "    end_to_right_flank : Norm(0, 0.1) , end_to_terminal : Norm(0, 0.1)\n",
      "    },\n",
      " flank_init=Const(0.0),\n",
      " prior=ProfileHMMTransitionPrior(match_comp=1, insert_comp=1, delete_comp=1, alpha_flank=7000, alpha_single=1000000000.0, alpha_global=10000.0, alpha_flank_compl=1, alpha_single_compl=1, alpha_global_compl=1),\n",
      " frozen_kernels={})\n",
      "emitter : MvnEmitter(scoring_model_config = ScoringModelConfig(lm_name=protT5, dim=32, activation=softmax, suffix=), ProfileHMMEmitter(\n",
      " emission_init=EmissionInitializer(),\n",
      " insertion_init=EmissionInitializer(),\n",
      " prior=JointEmissionPrior(AminoAcidPrior(comp_count=1), <learnMSA.protein_language_models.MvnPrior.MvnPrior object at 0x7f879c4115a0>, NullPrior()),\n",
      " frozen_insertions=True, ))\n",
      "max_surgery_runs : 4\n",
      "length_init_quantile : 0.5\n",
      "surgery_quantile : 0.5\n",
      "min_surgery_seqs : 100000.0\n",
      "len_mul : 0.8\n",
      "batch_size : functools.partial(<function get_adaptive_batch_size_with_language_model at 0x7f8858bbfbe0>, embedding_dim=32)\n",
      "learning_rate : 0.05\n",
      "epochs : [10, 4, 20]\n",
      "crop_long_seqs : 770\n",
      "use_prior : True\n",
      "dirichlet_mix_comp_count : 1\n",
      "use_anc_probs : True\n",
      "trainable_rate_matrices : False\n",
      "surgery_del : 0.5\n",
      "surgery_ins : 0.5\n",
      "num_rate_matrices : 1\n",
      "per_matrix_rate : False\n",
      "matrix_rate_l2 : 0.0\n",
      "shared_rate_matrix : False\n",
      "equilibrium_sample : False\n",
      "transposed : False\n",
      "encoder_initializer : [Const(-3), Const(shape=(4, 20, 20)), Const(shape=(4, 20))]\n",
      "model_criterion : AIC\n",
      "encoder_weight_extractor : None\n",
      "experimental_evolve_upper_half : False\n",
      "cluster_seq_id : 0.5\n",
      "use_language_model : True\n",
      "frozen_insertions : True\n",
      "allow_user_keys_in_config : False\n",
      "scoring_model_config : ScoringModelConfig(lm_name=protT5, dim=32, activation=softmax, suffix=)\n",
      "mvn_prior_components : 10\n",
      "use_l2 : False\n",
      "L2_match : 10.0\n",
      "L2_insert : 0.0\n",
      "temperature_mode : trainable\n",
      "conditionally_independent : True\n",
      "V2_emitter : True\n",
      "V2_full_covariance : False\n",
      "V2_temperature : 3.0\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beckerf/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/beckerf/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `DISABLE_TELEMETRY` is deprecated and will be removed in v5 of Transformers. Use `HF_HUB_DISABLE_TELEMETRY` instead.\n",
      "  warnings.warn(\n",
      "2024-02-06 15:11:04.151958: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing all embeddings (this may take a while).\n",
      "10% done.\n",
      "20% done.\n",
      "30% done.\n",
      "40% done.\n",
      "50% done.\n",
      "60% done.\n",
      "70% done.\n",
      "80% done.\n",
      "90% done.\n",
      "100% done.\n",
      "Fitting models of lengths [203 203 201 196] on 4514 sequences.\n",
      "Batch size= 100 Learning rate= 0.05\n",
      "Using sequence weights  [0.11111111 0.11111111 0.11111111 ... 0.01020408 0.1        0.03571429] .\n",
      "Using 1 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:13:15.471236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:15.471392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:15.471472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:15.471589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:15.471668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:15.471733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:13:17.073981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:17.074151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:17.074229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:17.074342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:17.074419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:17.074481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-02-06 15:13:20.448704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:20.448857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:20.448934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:20.449048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:20.449125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:13:20.449186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-02-06 15:13:24.069279: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x564a31514300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 - 28s - loss: 681.2725 - loglik: -6.1808e+02 - logprior: -6.2820e+01 - 28s/epoch - 412ms/step\n",
      "Epoch 2/10\n",
      "67/67 - 20s - loss: 522.7279 - loglik: -5.2296e+02 - logprior: 0.9082 - 20s/epoch - 297ms/step\n",
      "Epoch 3/10\n",
      "67/67 - 19s - loss: 507.8738 - loglik: -5.1518e+02 - logprior: 8.0145 - 19s/epoch - 291ms/step\n",
      "Epoch 4/10\n",
      "67/67 - 20s - loss: 501.9378 - loglik: -5.1203e+02 - logprior: 10.7974 - 20s/epoch - 292ms/step\n",
      "Epoch 5/10\n",
      "67/67 - 20s - loss: 498.1382 - loglik: -5.1019e+02 - logprior: 12.7633 - 20s/epoch - 294ms/step\n",
      "Epoch 6/10\n",
      "67/67 - 20s - loss: 501.3918 - loglik: -5.1486e+02 - logprior: 14.1830 - 20s/epoch - 296ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:15:24.074296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:24.074460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:24.074538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:24.074653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:24.074730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:24.074793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expansions model 0: [(0, 14), (5, 2), (6, 3), (24, 5), (36, 2), (43, 1), (46, 2), (52, 1), (54, 2), (78, 2), (79, 1), (82, 2), (95, 2), (96, 2), (107, 11), (108, 2), (110, 1), (139, 2), (143, 2), (147, 1), (152, 1), (155, 1), (158, 2), (160, 1), (162, 3), (170, 1), (180, 1), (181, 16), (191, 2), (192, 2), (203, 2)]\n",
      "discards model 0: [143]\n",
      "expansions model 1: [(0, 14), (7, 4), (8, 1), (24, 5), (36, 2), (44, 2), (52, 1), (55, 1), (78, 2), (80, 1), (83, 2), (84, 2), (95, 2), (96, 2), (107, 11), (108, 3), (109, 3), (117, 1), (142, 2), (151, 2), (154, 1), (157, 1), (158, 1), (160, 1), (161, 1), (165, 2), (178, 2), (181, 15), (189, 2), (203, 2)]\n",
      "discards model 1: [ 35  36 145 146 147]\n",
      "expansions model 2: [(0, 14), (5, 1), (6, 4), (7, 1), (8, 2), (22, 5), (35, 1), (43, 1), (44, 1), (55, 1), (62, 1), (80, 1), (83, 2), (84, 2), (95, 2), (96, 2), (107, 11), (108, 3), (109, 3), (137, 2), (143, 2), (151, 2), (159, 1), (162, 2), (163, 1), (170, 1), (179, 17), (186, 2), (187, 3), (201, 2)]\n",
      "discards model 2: [ 33  34  35 143 144]\n",
      "expansions model 3: [(0, 13), (7, 4), (8, 1), (9, 2), (23, 5), (35, 2), (38, 1), (39, 1), (40, 1), (51, 1), (53, 2), (55, 1), (75, 2), (77, 1), (80, 2), (81, 2), (92, 3), (93, 2), (104, 13), (105, 1), (106, 1), (114, 1), (133, 1), (138, 2), (147, 2), (150, 1), (153, 1), (157, 3), (161, 1), (163, 2), (173, 1), (175, 16), (184, 2), (185, 2), (196, 2)]\n",
      "discards model 3: [ 34  35 141 142 143 144]\n",
      "Re-initialized the encoder parameters.\n",
      "Fitting models of lengths [294, 289, 289, 288] on 4514 sequences.\n",
      "Batch size= 50 Learning rate= 0.05\n",
      "Using sequence weights  [0.11111111 0.11111111 0.11111111 ... 0.01020408 0.1        0.03571429] .\n",
      "Using 1 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:15:30.037570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:30.037737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:30.037816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:30.037931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:30.038009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:30.038072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:15:31.084744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:31.084903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:31.084981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:31.085096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:31.085176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:31.085239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-02-06 15:15:33.552766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:33.552928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:33.553009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:33.553124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:33.553201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-06 15:15:33.553263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 - 42s - loss: 532.2435 - loglik: -4.9874e+02 - logprior: -3.2885e+01 - 42s/epoch - 314ms/step\n",
      "Epoch 2/4\n",
      "134/134 - 35s - loss: 456.6059 - loglik: -4.9063e+02 - logprior: 34.6737 - 35s/epoch - 265ms/step\n",
      "Epoch 3/4\n",
      "134/134 - 35s - loss: 445.0650 - loglik: -4.8876e+02 - logprior: 44.3358 - 35s/epoch - 264ms/step\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m alignment_model \u001b[39m=\u001b[39m align(train_filename, \u001b[39m\"\u001b[39;49m\u001b[39mtest/data/interactive.alignment.fasta\u001b[39;49m\u001b[39m\"\u001b[39;49m) \n\u001b[1;32m      2\u001b[0m Visualize\u001b[39m.\u001b[39mprint_and_plot(alignment_model, alignment_model\u001b[39m.\u001b[39mbest_model)\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36malign\u001b[0;34m(filename, out_filename)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mwith\u001b[39;00m SequenceDataset(train_filename, fmt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfasta\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m data:\n\u001b[1;32m     15\u001b[0m     config[\u001b[39m\"\u001b[39m\u001b[39mcrop_long_seqs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mceil(\u001b[39m3\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmean(data\u001b[39m.\u001b[39mseq_lens)))\n\u001b[0;32m---> 16\u001b[0m     alignment_model \u001b[39m=\u001b[39m Align\u001b[39m.\u001b[39;49mrun_learnMSA(data,\n\u001b[1;32m     17\u001b[0m                                         out_filename,\n\u001b[1;32m     18\u001b[0m                                         config, \n\u001b[1;32m     19\u001b[0m                                         model_generator\u001b[39m=\u001b[39;49mmodel_gen,\n\u001b[1;32m     20\u001b[0m                                         batch_generator\u001b[39m=\u001b[39;49mbatch_gen,\n\u001b[1;32m     21\u001b[0m                                         sequence_weights\u001b[39m=\u001b[39;49mAlign\u001b[39m.\u001b[39;49mcompute_sequence_weights(train_filename, \u001b[39m\"\u001b[39;49m\u001b[39mtmp\u001b[39;49m\u001b[39m\"\u001b[39;49m, config[\u001b[39m\"\u001b[39;49m\u001b[39mcluster_seq_id\u001b[39;49m\u001b[39m\"\u001b[39;49m]),\n\u001b[1;32m     22\u001b[0m                                         verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     23\u001b[0m                                         align_insertions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m alignment_model\n",
      "File \u001b[0;32m~/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py:156\u001b[0m, in \u001b[0;36mrun_learnMSA\u001b[0;34m(data, out_filename, config, model_generator, batch_generator, subset_ids, align_insertions, insertion_aligner, aligner_threads, sequence_weights, verbose, initial_model_length_callback, select_best_for_comparison)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     t_a \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 156\u001b[0m     am \u001b[39m=\u001b[39m fit_and_align(data, \n\u001b[1;32m    157\u001b[0m                         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    158\u001b[0m                         model_generator\u001b[39m=\u001b[39;49mmodel_generator,\n\u001b[1;32m    159\u001b[0m                         batch_generator\u001b[39m=\u001b[39;49mbatch_generator,\n\u001b[1;32m    160\u001b[0m                         subset\u001b[39m=\u001b[39;49msubset, \n\u001b[1;32m    161\u001b[0m                         initial_model_length_callback\u001b[39m=\u001b[39;49minitial_model_length_callback,\n\u001b[1;32m    162\u001b[0m                         sequence_weights\u001b[39m=\u001b[39;49msequence_weights,\n\u001b[1;32m    163\u001b[0m                         verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    164\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m    165\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTime for alignment:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mt_a))\n",
      "File \u001b[0;32m~/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Align.py:88\u001b[0m, in \u001b[0;36mfit_and_align\u001b[0;34m(data, config, model_generator, batch_generator, subset, initial_model_length_callback, sequence_weights, verbose)\u001b[0m\n\u001b[1;32m     86\u001b[0m     decode_indices \u001b[39m=\u001b[39m full_length_estimate\n\u001b[1;32m     87\u001b[0m epochs_this_iteration \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m i\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m last_iteration \u001b[39melse\u001b[39;00m \u001b[39m2\u001b[39m]\n\u001b[0;32m---> 88\u001b[0m model, history \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39;49mfit_model(model_generator,\n\u001b[1;32m     89\u001b[0m                                   batch_generator,\n\u001b[1;32m     90\u001b[0m                                   data,\n\u001b[1;32m     91\u001b[0m                                   train_indices,\n\u001b[1;32m     92\u001b[0m                                   model_lengths, \n\u001b[1;32m     93\u001b[0m                                   config,\n\u001b[1;32m     94\u001b[0m                                   batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m     95\u001b[0m                                   epochs\u001b[39m=\u001b[39;49mepochs_this_iteration,\n\u001b[1;32m     96\u001b[0m                                   sequence_weights\u001b[39m=\u001b[39;49msequence_weights,\n\u001b[1;32m     97\u001b[0m                                   verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     98\u001b[0m am \u001b[39m=\u001b[39m AlignmentModel(data, batch_generator, decode_indices, batch_size\u001b[39m=\u001b[39mbatch_size, model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m last_iteration:\n",
      "File \u001b[0;32m~/brain/tmp_work/learnMSA/learnMSA/msa_hmm/Training.py:295\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(model_generator, batch_generator, data, indices, model_lengths, config, batch_size, epochs, sequence_weights, verbose)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[39massert\u001b[39;00m msa_hmm_layer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mCan not find a MsaHmmLayer in the specified model.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     \u001b[39m# class CustomCallback(tf.keras.callbacks.Callback):\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \n\u001b[1;32m    286\u001b[0m     \u001b[39m#     # def on_train_begin(self, logs=None):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[39m#         msa_hmm_layer.reverse_cell.emitter[0].step_counter.assign_add(1.)\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[39m# callbacks.append(CustomCallback())\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset, \n\u001b[1;32m    296\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    297\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m    298\u001b[0m                       callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    299\u001b[0m                     verbose \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mint\u001b[39;49m(verbose))\n\u001b[1;32m    300\u001b[0m tf\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39msetLevel(\u001b[39m'\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/mambaforge/envs/learnMSAdev/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alignment_model = align(train_filename, \"test/data/interactive.alignment.fasta\") \n",
    "Visualize.print_and_plot(alignment_model, alignment_model.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83bf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(369,), dtype=float32, numpy=\n",
       "array([2.24936139e-02, 6.23358214e-17, 3.47443699e-14, 1.49089886e-18,\n",
       "       1.50349558e-18, 1.55535401e-18, 3.98634235e-20, 1.69753214e-20,\n",
       "       1.68715506e-20, 5.58980880e-03, 2.08687163e-18, 1.83283740e-20,\n",
       "       6.14831038e-02, 2.60568913e-02, 1.66628394e-20, 2.44942768e-20,\n",
       "       1.20309098e-18, 2.19452616e-20, 3.77059433e-22, 3.63020990e-22,\n",
       "       2.76029073e-02, 3.71161303e-22, 3.54347180e-22, 3.24690938e-02,\n",
       "       3.64542040e-22, 3.57854797e-22, 5.95521927e-22, 1.31001620e-21,\n",
       "       1.48310566e-21, 1.09716672e-02, 7.65357747e-21, 3.57599004e-22,\n",
       "       3.60278001e-22, 3.66362428e-22, 5.19395582e-02, 3.58105894e-22,\n",
       "       3.87421506e-22, 2.24134251e-02, 3.70907933e-22, 3.50702820e-22,\n",
       "       3.72396116e-22, 3.54342712e-22, 3.79569525e-22, 4.15133394e-22,\n",
       "       3.60572113e-22, 3.60776081e-22, 3.58379434e-22, 3.56883551e-22,\n",
       "       3.63621635e-22, 3.62074105e-22, 3.69959356e-22, 1.32112559e-02,\n",
       "       3.69539203e-22, 3.58149137e-22, 7.84998592e-22, 3.85878064e-22,\n",
       "       4.03457358e-02, 3.82217144e-22, 4.83059190e-22, 3.85590566e-22,\n",
       "       9.30392083e-11, 4.64534082e-08, 5.24739631e-20, 9.25559852e-20,\n",
       "       3.44858130e-22, 3.77013111e-22, 3.59546342e-22, 3.70948701e-22,\n",
       "       3.84217317e-22, 3.33520041e-22, 2.95644831e-02, 3.63921756e-22,\n",
       "       5.08828764e-21, 3.59401797e-22, 5.86925277e-21, 3.59739758e-22,\n",
       "       3.73367589e-22, 3.07668501e-22, 1.11271627e-01, 1.65319023e-21,\n",
       "       8.00889305e-22, 5.72355650e-02, 4.22721731e-22, 3.81041451e-22,\n",
       "       3.20010148e-02, 3.65257871e-22, 1.02410480e-01, 4.25712037e-13,\n",
       "       2.60559786e-02, 2.83196511e-21, 3.69263392e-22, 3.76491326e-22,\n",
       "       3.72769796e-22, 1.67697450e-21, 8.29890911e-22, 2.44286435e-04,\n",
       "       9.67738368e-13, 2.12066626e-17, 6.80318251e-02, 3.29200087e-22,\n",
       "       6.85345640e-06, 2.26794649e-03, 3.25636789e-02, 2.81155799e-02,\n",
       "       6.47663235e-22, 3.29852936e-22, 3.84925881e-20, 3.64646473e-22,\n",
       "       9.23106805e-22, 5.33675585e-22, 5.89685012e-22, 6.10659675e-22,\n",
       "       3.58312715e-22, 3.51927435e-22, 3.61231980e-22, 4.98560780e-07,\n",
       "       4.33234948e-15, 1.98971894e-12, 2.12020334e-03, 5.10994978e-02,\n",
       "       3.10724096e-20, 2.61380252e-20, 1.51504424e-19, 3.87260899e-18,\n",
       "       3.90821807e-02, 3.36064540e-22, 2.93318951e-03, 3.65297832e-22,\n",
       "       8.88183061e-03, 7.92363397e-22, 3.50269464e-22, 2.42420398e-02,\n",
       "       1.35061396e-02, 3.79107568e-22, 4.10307971e-18, 2.90736953e-05,\n",
       "       1.87210184e-18, 5.98860028e-18, 1.77029333e-20, 2.10421242e-20,\n",
       "       1.76643919e-20, 5.65163984e-22, 2.51939744e-02, 3.60333360e-22,\n",
       "       3.07881456e-22, 3.43184761e-22, 4.10643198e-22, 3.48141433e-22,\n",
       "       2.49639060e-02, 3.11072780e-21, 4.01510208e-22, 3.69573054e-22,\n",
       "       3.57626671e-22, 1.81685837e-18, 6.03447808e-03, 1.56158665e-02,\n",
       "       9.82825065e-22, 2.96059018e-22, 3.26681816e-22, 1.22897618e-05,\n",
       "       3.10910320e-09, 2.58961154e-18, 1.76041704e-02, 3.67089114e-22,\n",
       "       2.52417460e-20, 3.62061962e-22, 3.79887467e-22, 3.57258645e-22,\n",
       "       3.75103108e-22, 5.79105996e-22, 3.64716726e-22, 3.44571641e-22,\n",
       "       3.85032204e-22, 3.92301487e-22, 3.60077537e-20, 2.31962026e-20,\n",
       "       1.99969475e-20, 4.15031927e-20, 1.87916658e-18, 2.73806502e-18,\n",
       "       4.21350077e-02, 2.90886872e-02, 1.10063011e-16, 1.51030885e-16,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       2.24936139e-02, 2.24936139e-02, 2.24936139e-02, 2.24936139e-02,\n",
       "       0.00000000e+00], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_model.model.layers[-3].cell.emitter[0].make_B()[0,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788bc8a-d9a8-4b72-a67a-e68fa6a1ec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE: 1tme\n",
      "HERE: 2mev\n",
      "HERE: 1bbt\n",
      "HERE: 1r1a\n",
      "HERE: 4rhv\n",
      "HERE: 2plv\n"
     ]
    }
   ],
   "source": [
    "!id_list=$(sed -n '/^>/p' {ref_filename} | sed 's/^.//') ; export MAX_N_PID_4_TCOFFEE=10000000 ; t_coffee -other_pg seq_reformat -in test/data/interactive.alignment.fasta -action +extract_seq_list ${{id_list[@]}} +rm_gap > test/data/interactive.projection.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd433dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "seq1       seq2          Sim   [ALL]           Tot  \n",
      "rhv           6          33.1    67.2 [100.0]   [20998]\n"
     ]
    }
   ],
   "source": [
    "!t_coffee -other_pg aln_compare -al1 {ref_filename} -al2 test/data/interactive.projection.fasta -compare_mode sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0a055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "488d3aa71b322ef168bf72fc4d82bebaa59a8882dc4050bd9af49d22feb8fb8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
